# âœ‹ Real-Time Sign language Translator  

## ğŸ“Œ Project Overview  
This project aims to build a system that can detect **hand gestures** using a webcam and convert them into **text in real-time**.  
It is primarily designed to help bridge the communication gap between people with **hearing/speech impairments** and others.  

Currently, the project is **under development**. The first version includes **hand detection** using OpenCV & MediaPipe.  
Upcoming features include **gesture classification, text generation, GUI integration**, and **speech output**.  

---

## ğŸ‘¨â€ğŸ’» Team Members  
- Imran Ali Reza â€“ 2211200010022  
- Sangeet Kumar Biswas â€“ 2211200010045  
- Shyam Mondal â€“ 2211200010034  
- Niladri Hati â€“ 2211200010056  

**Mentor:** Dr. Ankita Dhar  
**College:** Sister Nivedita University  

---

## ğŸš€ Features (Planned & Implemented)  
- [x] Hand detection using OpenCV + MediaPipe  
- [ ] Gesture dataset collection (CSV format)  
- [ ] Gesture classification using ML (Scikit-learn / TensorFlow)  
- [ ] GUI with Tkinter for real-time display  
- [ ] Conversion of gestures into text  
- [ ] Optional speech output (gTTS / pyttsx3)  

---

## ğŸ› ï¸ Technologies & Libraries  
- **Python 3.10**  
- **OpenCV** â€“ Webcam access and image processing  
- **MediaPipe** â€“ Hand tracking and landmark detection  
- **Tkinter** â€“ GUI (to be added)  
- **Scikit-learn / TensorFlow** â€“ Machine Learning model training  
- **NumPy, Pandas** â€“ Data handling  

---

## ğŸ“‚ Project Structure (so far)  
SignLanguageToText/  
â”‚-- handmodule.py # Hand detection module  
â”‚-- main.py # Main file (GUI + detection logic)  
â”‚-- requirements.txt # Dependencies  
â”‚-- README.md # Project documentation  

---

## âš™ï¸ Installation  

1. **Clone the repository**  
   ```bash
   git clone https://github.com/SANGEET240/Real-Time-sign-language-translator.git
   cd SignLanguageToText

2. **Create a virtual environment (recommended)**  
   ```bash
   "python -m venv venv"  
   "source venv/Scripts/activate"   # For Windows  

3. **Install dependencies**  
   ```bash
   "pip install -r requirements.txt"

4. **Run the project**
"python main.py"

ğŸ“Š **Current Progress**
Hand detection works successfully using MediaPipe.
Initial GUI setup in Tkinter is in progress.
Next steps: gesture dataset collection & model training.

ğŸ”® **Future Scope**
Support for full sign language vocabulary.
Two-way communication (text-to-speech & speech-to-sign).
Mobile or web-based deployment.

ğŸ“– **References**  
OpenCV Documentation - https://opencv.org/  
MediaPipe Documentation - https://developers.google.com/mediapipe  
Scikit-learn Documentation - https://scikit-learn.org/stable/  
Python Official Docs - https://docs.python.org/3/  

âš ï¸ **Note**
This project is still incomplete and under active development. Contributions from teammates are welcome. ğŸš€